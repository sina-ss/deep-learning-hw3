{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11b9bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Attempting to load local MNIST dataset...\n",
      "Successfully loaded local dataset: 60000 training samples\n",
      "Dataset loaded: 60000 training samples\n",
      "Networks initialized\n",
      "Generator parameters: 1489936\n",
      "Discriminator parameters: 566273\n",
      "Starting training...\n",
      "Epoch [1/50] Batch [0/938] D_loss: 1.3795 G_loss: 0.6926 D_real_acc: 0.9219 D_fake_acc: 0.3438\n",
      "Epoch [1/50] Batch [100/938] D_loss: 1.3003 G_loss: 0.9508 D_real_acc: 0.5156 D_fake_acc: 0.8281\n",
      "Epoch [1/50] Batch [200/938] D_loss: 1.5763 G_loss: 0.5817 D_real_acc: 0.5000 D_fake_acc: 0.1094\n",
      "Epoch [1/50] Batch [300/938] D_loss: 1.2491 G_loss: 0.7461 D_real_acc: 0.7500 D_fake_acc: 0.6406\n",
      "Epoch [1/50] Batch [400/938] D_loss: 1.2005 G_loss: 0.9441 D_real_acc: 0.7031 D_fake_acc: 0.7656\n",
      "Epoch [1/50] Batch [500/938] D_loss: 1.1927 G_loss: 0.6048 D_real_acc: 0.4375 D_fake_acc: 0.9688\n",
      "Epoch [1/50] Batch [600/938] D_loss: 1.2234 G_loss: 1.3211 D_real_acc: 0.9219 D_fake_acc: 0.3906\n",
      "Epoch [1/50] Batch [700/938] D_loss: 1.1460 G_loss: 1.3297 D_real_acc: 0.8594 D_fake_acc: 0.5156\n",
      "Epoch [1/50] Batch [800/938] D_loss: 1.2893 G_loss: 1.0803 D_real_acc: 0.7031 D_fake_acc: 0.5469\n",
      "Epoch [1/50] Batch [900/938] D_loss: 1.1829 G_loss: 0.9657 D_real_acc: 0.6875 D_fake_acc: 0.6250\n",
      "Epoch [1/50] Average - D_loss: 1.2278 G_loss: 0.9842 D_real_acc: 0.7604 D_fake_acc: 0.5298\n",
      "Generated images saved to generated_images/epoch_01.png\n",
      "Epoch [2/50] Batch [0/938] D_loss: 1.0832 G_loss: 1.0481 D_real_acc: 0.6094 D_fake_acc: 0.9219\n",
      "Epoch [2/50] Batch [100/938] D_loss: 1.2285 G_loss: 1.5040 D_real_acc: 0.8906 D_fake_acc: 0.3594\n",
      "Epoch [2/50] Batch [200/938] D_loss: 1.2061 G_loss: 1.0747 D_real_acc: 0.8594 D_fake_acc: 0.4844\n",
      "Epoch [2/50] Batch [300/938] D_loss: 1.2322 G_loss: 1.1015 D_real_acc: 0.5781 D_fake_acc: 0.7812\n",
      "Epoch [2/50] Batch [400/938] D_loss: 1.0106 G_loss: 0.9662 D_real_acc: 0.6875 D_fake_acc: 0.7969\n",
      "Epoch [2/50] Batch [500/938] D_loss: 1.1730 G_loss: 1.1560 D_real_acc: 0.5312 D_fake_acc: 0.7188\n",
      "Epoch [2/50] Batch [600/938] D_loss: 1.0362 G_loss: 1.0744 D_real_acc: 0.6875 D_fake_acc: 0.8594\n",
      "Epoch [2/50] Batch [700/938] D_loss: 1.1270 G_loss: 0.9265 D_real_acc: 0.3906 D_fake_acc: 0.9531\n",
      "Epoch [2/50] Batch [800/938] D_loss: 1.2524 G_loss: 1.0813 D_real_acc: 0.3281 D_fake_acc: 0.9375\n",
      "Epoch [2/50] Batch [900/938] D_loss: 1.2036 G_loss: 0.9216 D_real_acc: 0.6094 D_fake_acc: 0.7031\n",
      "Epoch [2/50] Average - D_loss: 1.1981 G_loss: 1.0787 D_real_acc: 0.6158 D_fake_acc: 0.7303\n",
      "Epoch [3/50] Batch [0/938] D_loss: 1.3271 G_loss: 1.5682 D_real_acc: 0.8281 D_fake_acc: 0.2969\n",
      "Epoch [3/50] Batch [100/938] D_loss: 1.2428 G_loss: 1.1448 D_real_acc: 0.6094 D_fake_acc: 0.5469\n",
      "Epoch [3/50] Batch [200/938] D_loss: 1.2812 G_loss: 1.1646 D_real_acc: 0.7188 D_fake_acc: 0.4688\n",
      "Epoch [3/50] Batch [300/938] D_loss: 1.2742 G_loss: 0.8472 D_real_acc: 0.4219 D_fake_acc: 0.7969\n",
      "Epoch [3/50] Batch [400/938] D_loss: 1.1518 G_loss: 0.9372 D_real_acc: 0.7812 D_fake_acc: 0.7188\n",
      "Epoch [3/50] Batch [500/938] D_loss: 1.2745 G_loss: 0.7910 D_real_acc: 0.5781 D_fake_acc: 0.6719\n",
      "Epoch [3/50] Batch [600/938] D_loss: 1.2703 G_loss: 1.2319 D_real_acc: 0.7812 D_fake_acc: 0.4844\n",
      "Epoch [3/50] Batch [700/938] D_loss: 1.1309 G_loss: 0.9556 D_real_acc: 0.6406 D_fake_acc: 0.8281\n",
      "Epoch [3/50] Batch [800/938] D_loss: 1.3056 G_loss: 0.8233 D_real_acc: 0.5625 D_fake_acc: 0.7188\n",
      "Epoch [3/50] Batch [900/938] D_loss: 1.2341 G_loss: 0.9134 D_real_acc: 0.6719 D_fake_acc: 0.7031\n",
      "Epoch [3/50] Average - D_loss: 1.2467 G_loss: 0.9531 D_real_acc: 0.5753 D_fake_acc: 0.7181\n",
      "Epoch [4/50] Batch [0/938] D_loss: 1.2654 G_loss: 0.7804 D_real_acc: 0.5156 D_fake_acc: 0.7812\n",
      "Epoch [4/50] Batch [100/938] D_loss: 1.2339 G_loss: 0.5701 D_real_acc: 0.5156 D_fake_acc: 0.8125\n",
      "Epoch [4/50] Batch [200/938] D_loss: 1.2954 G_loss: 0.7858 D_real_acc: 0.4844 D_fake_acc: 0.7812\n",
      "Epoch [4/50] Batch [300/938] D_loss: 1.3680 G_loss: 0.9315 D_real_acc: 0.4375 D_fake_acc: 0.7969\n",
      "Epoch [4/50] Batch [400/938] D_loss: 1.3044 G_loss: 0.9520 D_real_acc: 0.3281 D_fake_acc: 0.9062\n",
      "Epoch [4/50] Batch [500/938] D_loss: 1.2414 G_loss: 0.7211 D_real_acc: 0.5781 D_fake_acc: 0.6562\n",
      "Epoch [4/50] Batch [600/938] D_loss: 1.2372 G_loss: 1.0816 D_real_acc: 0.7812 D_fake_acc: 0.4688\n",
      "Epoch [4/50] Batch [700/938] D_loss: 1.2983 G_loss: 0.7767 D_real_acc: 0.5781 D_fake_acc: 0.6875\n",
      "Epoch [4/50] Batch [800/938] D_loss: 1.2926 G_loss: 0.9556 D_real_acc: 0.3281 D_fake_acc: 0.9062\n",
      "Epoch [4/50] Batch [900/938] D_loss: 1.2579 G_loss: 0.9610 D_real_acc: 0.8438 D_fake_acc: 0.4844\n",
      "Epoch [4/50] Average - D_loss: 1.2754 G_loss: 0.8955 D_real_acc: 0.5510 D_fake_acc: 0.7108\n",
      "Epoch [5/50] Batch [0/938] D_loss: 1.2414 G_loss: 0.8432 D_real_acc: 0.5469 D_fake_acc: 0.7031\n",
      "Epoch [5/50] Batch [100/938] D_loss: 1.2600 G_loss: 1.0000 D_real_acc: 0.6562 D_fake_acc: 0.6250\n",
      "Epoch [5/50] Batch [200/938] D_loss: 1.2381 G_loss: 0.8725 D_real_acc: 0.5781 D_fake_acc: 0.6875\n",
      "Epoch [5/50] Batch [300/938] D_loss: 1.1939 G_loss: 0.8652 D_real_acc: 0.5469 D_fake_acc: 0.7969\n",
      "Epoch [5/50] Batch [400/938] D_loss: 1.3975 G_loss: 0.9031 D_real_acc: 0.3594 D_fake_acc: 0.6406\n",
      "Epoch [5/50] Batch [500/938] D_loss: 1.3682 G_loss: 0.8295 D_real_acc: 0.5156 D_fake_acc: 0.7500\n",
      "Epoch [5/50] Batch [600/938] D_loss: 1.1636 G_loss: 0.9176 D_real_acc: 0.6250 D_fake_acc: 0.7812\n",
      "Epoch [5/50] Batch [700/938] D_loss: 1.3373 G_loss: 0.8188 D_real_acc: 0.5781 D_fake_acc: 0.6562\n",
      "Epoch [5/50] Batch [800/938] D_loss: 1.3543 G_loss: 0.8550 D_real_acc: 0.5000 D_fake_acc: 0.6562\n",
      "Epoch [5/50] Batch [900/938] D_loss: 1.3313 G_loss: 0.7465 D_real_acc: 0.4531 D_fake_acc: 0.7656\n",
      "Epoch [5/50] Average - D_loss: 1.2977 G_loss: 0.8552 D_real_acc: 0.5294 D_fake_acc: 0.7032\n",
      "Generated images saved to generated_images/epoch_05.png\n",
      "Epoch [6/50] Batch [0/938] D_loss: 1.3295 G_loss: 0.8997 D_real_acc: 0.2969 D_fake_acc: 0.8438\n",
      "Epoch [6/50] Batch [100/938] D_loss: 1.2971 G_loss: 0.8439 D_real_acc: 0.5625 D_fake_acc: 0.6719\n",
      "Epoch [6/50] Batch [200/938] D_loss: 1.3591 G_loss: 0.8280 D_real_acc: 0.4844 D_fake_acc: 0.5938\n",
      "Epoch [6/50] Batch [300/938] D_loss: 1.3390 G_loss: 0.7429 D_real_acc: 0.6562 D_fake_acc: 0.5625\n",
      "Epoch [6/50] Batch [400/938] D_loss: 1.2950 G_loss: 0.8060 D_real_acc: 0.4844 D_fake_acc: 0.7812\n",
      "Epoch [6/50] Batch [500/938] D_loss: 1.2346 G_loss: 0.8654 D_real_acc: 0.6719 D_fake_acc: 0.6250\n",
      "Epoch [6/50] Batch [600/938] D_loss: 1.3291 G_loss: 0.7455 D_real_acc: 0.4844 D_fake_acc: 0.7031\n",
      "Epoch [6/50] Batch [700/938] D_loss: 1.3656 G_loss: 0.8274 D_real_acc: 0.4844 D_fake_acc: 0.5469\n",
      "Epoch [6/50] Batch [800/938] D_loss: 1.2815 G_loss: 0.7704 D_real_acc: 0.3750 D_fake_acc: 0.7969\n",
      "Epoch [6/50] Batch [900/938] D_loss: 1.2720 G_loss: 0.7919 D_real_acc: 0.6562 D_fake_acc: 0.6250\n",
      "Epoch [6/50] Average - D_loss: 1.3228 G_loss: 0.8140 D_real_acc: 0.5019 D_fake_acc: 0.6920\n",
      "Epoch [7/50] Batch [0/938] D_loss: 1.3592 G_loss: 0.8114 D_real_acc: 0.3281 D_fake_acc: 0.7969\n",
      "Epoch [7/50] Batch [100/938] D_loss: 1.3401 G_loss: 0.8039 D_real_acc: 0.4688 D_fake_acc: 0.7031\n",
      "Epoch [7/50] Batch [200/938] D_loss: 1.3834 G_loss: 0.8768 D_real_acc: 0.3750 D_fake_acc: 0.7344\n",
      "Epoch [7/50] Batch [300/938] D_loss: 1.3154 G_loss: 0.7910 D_real_acc: 0.6094 D_fake_acc: 0.5625\n",
      "Epoch [7/50] Batch [400/938] D_loss: 1.3981 G_loss: 0.8441 D_real_acc: 0.5312 D_fake_acc: 0.5312\n",
      "Epoch [7/50] Batch [500/938] D_loss: 1.3121 G_loss: 0.8229 D_real_acc: 0.4844 D_fake_acc: 0.7344\n",
      "Epoch [7/50] Batch [600/938] D_loss: 1.2561 G_loss: 0.8568 D_real_acc: 0.7500 D_fake_acc: 0.5156\n",
      "Epoch [7/50] Batch [700/938] D_loss: 1.2475 G_loss: 0.7683 D_real_acc: 0.6250 D_fake_acc: 0.5781\n",
      "Epoch [7/50] Batch [800/938] D_loss: 1.3492 G_loss: 0.8063 D_real_acc: 0.5312 D_fake_acc: 0.6250\n",
      "Epoch [7/50] Batch [900/938] D_loss: 1.3411 G_loss: 0.7654 D_real_acc: 0.3750 D_fake_acc: 0.8281\n",
      "Epoch [7/50] Average - D_loss: 1.3342 G_loss: 0.7992 D_real_acc: 0.4980 D_fake_acc: 0.6825\n",
      "Epoch [8/50] Batch [0/938] D_loss: 1.2882 G_loss: 0.8004 D_real_acc: 0.6094 D_fake_acc: 0.6875\n",
      "Epoch [8/50] Batch [100/938] D_loss: 1.2961 G_loss: 0.6949 D_real_acc: 0.6250 D_fake_acc: 0.6875\n",
      "Epoch [8/50] Batch [200/938] D_loss: 1.3692 G_loss: 0.7612 D_real_acc: 0.4688 D_fake_acc: 0.6719\n",
      "Epoch [8/50] Batch [300/938] D_loss: 1.3498 G_loss: 0.7954 D_real_acc: 0.4219 D_fake_acc: 0.6250\n",
      "Epoch [8/50] Batch [400/938] D_loss: 1.4175 G_loss: 0.7781 D_real_acc: 0.4844 D_fake_acc: 0.5469\n",
      "Epoch [8/50] Batch [500/938] D_loss: 1.3949 G_loss: 0.8149 D_real_acc: 0.3125 D_fake_acc: 0.7969\n",
      "Epoch [8/50] Batch [600/938] D_loss: 1.3861 G_loss: 0.7414 D_real_acc: 0.4062 D_fake_acc: 0.7031\n",
      "Epoch [8/50] Batch [700/938] D_loss: 1.3250 G_loss: 0.7504 D_real_acc: 0.4375 D_fake_acc: 0.7031\n",
      "Epoch [8/50] Batch [800/938] D_loss: 1.3442 G_loss: 0.7288 D_real_acc: 0.6875 D_fake_acc: 0.4375\n",
      "Epoch [8/50] Batch [900/938] D_loss: 1.3031 G_loss: 0.7389 D_real_acc: 0.8125 D_fake_acc: 0.4219\n",
      "Epoch [8/50] Average - D_loss: 1.3459 G_loss: 0.7758 D_real_acc: 0.4858 D_fake_acc: 0.6693\n",
      "Epoch [9/50] Batch [0/938] D_loss: 1.3880 G_loss: 0.8633 D_real_acc: 0.1406 D_fake_acc: 0.8906\n",
      "Epoch [9/50] Batch [100/938] D_loss: 1.3201 G_loss: 0.7916 D_real_acc: 0.5156 D_fake_acc: 0.7656\n",
      "Epoch [9/50] Batch [200/938] D_loss: 1.3896 G_loss: 0.7508 D_real_acc: 0.3281 D_fake_acc: 0.7500\n",
      "Epoch [9/50] Batch [300/938] D_loss: 1.3667 G_loss: 0.7949 D_real_acc: 0.2500 D_fake_acc: 0.8125\n",
      "Epoch [9/50] Batch [400/938] D_loss: 1.3966 G_loss: 0.7494 D_real_acc: 0.4531 D_fake_acc: 0.5938\n",
      "Epoch [9/50] Batch [500/938] D_loss: 1.4083 G_loss: 0.8133 D_real_acc: 0.2500 D_fake_acc: 0.6562\n",
      "Epoch [9/50] Batch [600/938] D_loss: 1.3051 G_loss: 0.7304 D_real_acc: 0.6094 D_fake_acc: 0.6094\n",
      "Epoch [9/50] Batch [700/938] D_loss: 1.3234 G_loss: 0.7305 D_real_acc: 0.6094 D_fake_acc: 0.6094\n",
      "Epoch [9/50] Batch [800/938] D_loss: 1.3368 G_loss: 0.6988 D_real_acc: 0.7812 D_fake_acc: 0.4062\n",
      "Epoch [9/50] Batch [900/938] D_loss: 1.4190 G_loss: 0.7762 D_real_acc: 0.3750 D_fake_acc: 0.6094\n",
      "Epoch [9/50] Average - D_loss: 1.3575 G_loss: 0.7582 D_real_acc: 0.4751 D_fake_acc: 0.6554\n",
      "Epoch [10/50] Batch [0/938] D_loss: 1.3955 G_loss: 0.7535 D_real_acc: 0.2188 D_fake_acc: 0.8125\n",
      "Epoch [10/50] Batch [100/938] D_loss: 1.3732 G_loss: 0.7463 D_real_acc: 0.4375 D_fake_acc: 0.7344\n",
      "Epoch [10/50] Batch [200/938] D_loss: 1.3679 G_loss: 0.7321 D_real_acc: 0.5000 D_fake_acc: 0.6719\n",
      "Epoch [10/50] Batch [300/938] D_loss: 1.3598 G_loss: 0.7595 D_real_acc: 0.3906 D_fake_acc: 0.6875\n",
      "Epoch [10/50] Batch [400/938] D_loss: 1.3693 G_loss: 0.7717 D_real_acc: 0.3906 D_fake_acc: 0.7031\n",
      "Epoch [10/50] Batch [500/938] D_loss: 1.3670 G_loss: 0.7480 D_real_acc: 0.4688 D_fake_acc: 0.6875\n",
      "Epoch [10/50] Batch [600/938] D_loss: 1.3956 G_loss: 0.8240 D_real_acc: 0.2188 D_fake_acc: 0.7812\n",
      "Epoch [10/50] Batch [700/938] D_loss: 1.4088 G_loss: 0.7572 D_real_acc: 0.3750 D_fake_acc: 0.6094\n",
      "Epoch [10/50] Batch [800/938] D_loss: 1.3915 G_loss: 0.8054 D_real_acc: 0.3125 D_fake_acc: 0.6250\n",
      "Epoch [10/50] Batch [900/938] D_loss: 1.3867 G_loss: 0.7621 D_real_acc: 0.5625 D_fake_acc: 0.4531\n",
      "Epoch [10/50] Average - D_loss: 1.3605 G_loss: 0.7507 D_real_acc: 0.4631 D_fake_acc: 0.6583\n",
      "Generated images saved to generated_images/epoch_10.png\n",
      "Epoch [11/50] Batch [0/938] D_loss: 1.3731 G_loss: 0.6818 D_real_acc: 0.6562 D_fake_acc: 0.4375\n",
      "Epoch [11/50] Batch [100/938] D_loss: 1.3360 G_loss: 0.7511 D_real_acc: 0.5312 D_fake_acc: 0.6875\n",
      "Epoch [11/50] Batch [200/938] D_loss: 1.3808 G_loss: 0.7640 D_real_acc: 0.3125 D_fake_acc: 0.7344\n",
      "Epoch [11/50] Batch [300/938] D_loss: 1.3954 G_loss: 0.7820 D_real_acc: 0.1094 D_fake_acc: 0.8750\n",
      "Epoch [11/50] Batch [400/938] D_loss: 1.3867 G_loss: 0.7190 D_real_acc: 0.3594 D_fake_acc: 0.5781\n",
      "Epoch [11/50] Batch [500/938] D_loss: 1.3799 G_loss: 0.7669 D_real_acc: 0.5469 D_fake_acc: 0.5781\n",
      "Epoch [11/50] Batch [600/938] D_loss: 1.3338 G_loss: 0.7154 D_real_acc: 0.4844 D_fake_acc: 0.7656\n",
      "Epoch [11/50] Batch [700/938] D_loss: 1.3746 G_loss: 0.7178 D_real_acc: 0.5625 D_fake_acc: 0.5781\n",
      "Epoch [11/50] Batch [800/938] D_loss: 1.3234 G_loss: 0.7774 D_real_acc: 0.5469 D_fake_acc: 0.6562\n",
      "Epoch [11/50] Batch [900/938] D_loss: 1.3761 G_loss: 0.6582 D_real_acc: 0.6562 D_fake_acc: 0.3594\n",
      "Epoch [11/50] Average - D_loss: 1.3658 G_loss: 0.7439 D_real_acc: 0.4566 D_fake_acc: 0.6509\n",
      "Epoch [12/50] Batch [0/938] D_loss: 1.3779 G_loss: 0.7368 D_real_acc: 0.3906 D_fake_acc: 0.6719\n",
      "Epoch [12/50] Batch [100/938] D_loss: 1.3291 G_loss: 0.7580 D_real_acc: 0.4531 D_fake_acc: 0.8125\n",
      "Epoch [12/50] Batch [200/938] D_loss: 1.3796 G_loss: 0.7303 D_real_acc: 0.4531 D_fake_acc: 0.6094\n",
      "Epoch [12/50] Batch [300/938] D_loss: 1.3510 G_loss: 0.7274 D_real_acc: 0.4062 D_fake_acc: 0.7344\n",
      "Epoch [12/50] Batch [400/938] D_loss: 1.3589 G_loss: 0.7399 D_real_acc: 0.3438 D_fake_acc: 0.7188\n",
      "Epoch [12/50] Batch [500/938] D_loss: 1.3731 G_loss: 0.7508 D_real_acc: 0.3438 D_fake_acc: 0.7812\n",
      "Epoch [12/50] Batch [600/938] D_loss: 1.3530 G_loss: 0.7187 D_real_acc: 0.5781 D_fake_acc: 0.5938\n",
      "Epoch [12/50] Batch [700/938] D_loss: 1.3706 G_loss: 0.7712 D_real_acc: 0.2656 D_fake_acc: 0.7969\n",
      "Epoch [12/50] Batch [800/938] D_loss: 1.3443 G_loss: 0.6911 D_real_acc: 0.7031 D_fake_acc: 0.4219\n",
      "Epoch [12/50] Batch [900/938] D_loss: 1.3736 G_loss: 0.7331 D_real_acc: 0.5625 D_fake_acc: 0.6719\n",
      "Epoch [12/50] Average - D_loss: 1.3676 G_loss: 0.7373 D_real_acc: 0.4614 D_fake_acc: 0.6454\n",
      "Epoch [13/50] Batch [0/938] D_loss: 1.3820 G_loss: 0.6966 D_real_acc: 0.5469 D_fake_acc: 0.5000\n",
      "Epoch [13/50] Batch [100/938] D_loss: 1.3846 G_loss: 0.7392 D_real_acc: 0.4844 D_fake_acc: 0.5781\n",
      "Epoch [13/50] Batch [200/938] D_loss: 1.3868 G_loss: 0.7219 D_real_acc: 0.5625 D_fake_acc: 0.5938\n",
      "Epoch [13/50] Batch [300/938] D_loss: 1.3449 G_loss: 0.7517 D_real_acc: 0.4375 D_fake_acc: 0.7500\n",
      "Epoch [13/50] Batch [400/938] D_loss: 1.3556 G_loss: 0.7181 D_real_acc: 0.5469 D_fake_acc: 0.6875\n",
      "Epoch [13/50] Batch [500/938] D_loss: 1.3761 G_loss: 0.7608 D_real_acc: 0.5000 D_fake_acc: 0.5625\n",
      "Epoch [13/50] Batch [600/938] D_loss: 1.4156 G_loss: 0.7628 D_real_acc: 0.3125 D_fake_acc: 0.6562\n",
      "Epoch [13/50] Batch [700/938] D_loss: 1.3805 G_loss: 0.7075 D_real_acc: 0.5312 D_fake_acc: 0.4219\n",
      "Epoch [13/50] Batch [800/938] D_loss: 1.3163 G_loss: 0.7038 D_real_acc: 0.4375 D_fake_acc: 0.7188\n",
      "Epoch [13/50] Batch [900/938] D_loss: 1.3831 G_loss: 0.7143 D_real_acc: 0.2812 D_fake_acc: 0.7812\n",
      "Epoch [13/50] Average - D_loss: 1.3680 G_loss: 0.7378 D_real_acc: 0.4672 D_fake_acc: 0.6387\n",
      "Epoch [14/50] Batch [0/938] D_loss: 1.3938 G_loss: 0.7235 D_real_acc: 0.3438 D_fake_acc: 0.6719\n",
      "Epoch [14/50] Batch [100/938] D_loss: 1.3556 G_loss: 0.7112 D_real_acc: 0.6250 D_fake_acc: 0.5312\n",
      "Epoch [14/50] Batch [200/938] D_loss: 1.3900 G_loss: 0.7026 D_real_acc: 0.3906 D_fake_acc: 0.6562\n",
      "Epoch [14/50] Batch [300/938] D_loss: 1.3686 G_loss: 0.7122 D_real_acc: 0.4844 D_fake_acc: 0.5938\n",
      "Epoch [14/50] Batch [400/938] D_loss: 1.3533 G_loss: 0.7356 D_real_acc: 0.3906 D_fake_acc: 0.8125\n",
      "Epoch [14/50] Batch [500/938] D_loss: 1.3725 G_loss: 0.7334 D_real_acc: 0.3750 D_fake_acc: 0.7031\n",
      "Epoch [14/50] Batch [600/938] D_loss: 1.3597 G_loss: 0.7062 D_real_acc: 0.5000 D_fake_acc: 0.6094\n",
      "Epoch [14/50] Batch [700/938] D_loss: 1.3961 G_loss: 0.6969 D_real_acc: 0.4375 D_fake_acc: 0.5000\n",
      "Epoch [14/50] Batch [800/938] D_loss: 1.3746 G_loss: 0.7030 D_real_acc: 0.4375 D_fake_acc: 0.5312\n",
      "Epoch [14/50] Batch [900/938] D_loss: 1.3326 G_loss: 0.7460 D_real_acc: 0.5625 D_fake_acc: 0.6094\n",
      "Epoch [14/50] Average - D_loss: 1.3712 G_loss: 0.7298 D_real_acc: 0.4672 D_fake_acc: 0.6255\n",
      "Epoch [15/50] Batch [0/938] D_loss: 1.3952 G_loss: 0.7167 D_real_acc: 0.4531 D_fake_acc: 0.5938\n",
      "Epoch [15/50] Batch [100/938] D_loss: 1.3820 G_loss: 0.7492 D_real_acc: 0.3281 D_fake_acc: 0.6875\n",
      "Epoch [15/50] Batch [200/938] D_loss: 1.3670 G_loss: 0.8138 D_real_acc: 0.1562 D_fake_acc: 0.9375\n",
      "Epoch [15/50] Batch [300/938] D_loss: 1.3439 G_loss: 0.7179 D_real_acc: 0.7031 D_fake_acc: 0.4375\n",
      "Epoch [15/50] Batch [400/938] D_loss: 1.3673 G_loss: 0.7261 D_real_acc: 0.5156 D_fake_acc: 0.6094\n",
      "Epoch [15/50] Batch [500/938] D_loss: 1.3914 G_loss: 0.7693 D_real_acc: 0.3125 D_fake_acc: 0.7656\n",
      "Epoch [15/50] Batch [600/938] D_loss: 1.3692 G_loss: 0.7741 D_real_acc: 0.4844 D_fake_acc: 0.5312\n",
      "Epoch [15/50] Batch [700/938] D_loss: 1.3506 G_loss: 0.6857 D_real_acc: 0.6406 D_fake_acc: 0.5625\n",
      "Epoch [15/50] Batch [800/938] D_loss: 1.3640 G_loss: 0.7238 D_real_acc: 0.4531 D_fake_acc: 0.6875\n",
      "Epoch [15/50] Batch [900/938] D_loss: 1.3144 G_loss: 0.7137 D_real_acc: 0.5938 D_fake_acc: 0.6562\n",
      "Epoch [15/50] Average - D_loss: 1.3710 G_loss: 0.7292 D_real_acc: 0.4688 D_fake_acc: 0.6271\n",
      "Generated images saved to generated_images/epoch_15.png\n",
      "Epoch [16/50] Batch [0/938] D_loss: 1.3787 G_loss: 0.7296 D_real_acc: 0.4844 D_fake_acc: 0.5156\n",
      "Epoch [16/50] Batch [100/938] D_loss: 1.3693 G_loss: 0.7291 D_real_acc: 0.3125 D_fake_acc: 0.7031\n",
      "Epoch [16/50] Batch [200/938] D_loss: 1.3911 G_loss: 0.7129 D_real_acc: 0.5312 D_fake_acc: 0.6094\n",
      "Epoch [16/50] Batch [300/938] D_loss: 1.3755 G_loss: 0.7592 D_real_acc: 0.2344 D_fake_acc: 0.8281\n",
      "Epoch [16/50] Batch [400/938] D_loss: 1.3537 G_loss: 0.7196 D_real_acc: 0.5938 D_fake_acc: 0.4844\n",
      "Epoch [16/50] Batch [500/938] D_loss: 1.3768 G_loss: 0.7573 D_real_acc: 0.2812 D_fake_acc: 0.7656\n",
      "Epoch [16/50] Batch [600/938] D_loss: 1.3642 G_loss: 0.7236 D_real_acc: 0.5469 D_fake_acc: 0.5000\n",
      "Epoch [16/50] Batch [700/938] D_loss: 1.3581 G_loss: 0.7639 D_real_acc: 0.4375 D_fake_acc: 0.6875\n",
      "Epoch [16/50] Batch [800/938] D_loss: 1.3800 G_loss: 0.7040 D_real_acc: 0.4844 D_fake_acc: 0.6250\n",
      "Epoch [16/50] Batch [900/938] D_loss: 1.3935 G_loss: 0.7473 D_real_acc: 0.3125 D_fake_acc: 0.7031\n",
      "Epoch [16/50] Average - D_loss: 1.3741 G_loss: 0.7251 D_real_acc: 0.4635 D_fake_acc: 0.6241\n",
      "Epoch [17/50] Batch [0/938] D_loss: 1.3732 G_loss: 0.7290 D_real_acc: 0.2656 D_fake_acc: 0.7812\n",
      "Epoch [17/50] Batch [100/938] D_loss: 1.3939 G_loss: 0.7231 D_real_acc: 0.3750 D_fake_acc: 0.6250\n",
      "Epoch [17/50] Batch [200/938] D_loss: 1.3575 G_loss: 0.7336 D_real_acc: 0.2969 D_fake_acc: 0.7344\n",
      "Epoch [17/50] Batch [300/938] D_loss: 1.4089 G_loss: 0.7080 D_real_acc: 0.2656 D_fake_acc: 0.6562\n",
      "Epoch [17/50] Batch [400/938] D_loss: 1.3625 G_loss: 0.6765 D_real_acc: 0.5781 D_fake_acc: 0.5469\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0002\n",
    "NOISE_DIM = 100\n",
    "NUM_EPOCHS = 50\n",
    "BETA1 = 0.5  # Beta1 for Adam optimizer\n",
    "\n",
    "# Create directory for saving images\n",
    "os.makedirs('generated_images', exist_ok=True)\n",
    "\n",
    "# Data preprocessing and loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Load MNIST dataset from local files\n",
    "# First, let's try to use the local data without downloading\n",
    "try:\n",
    "    print(\"Attempting to load local MNIST dataset...\")\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=False, transform=transform)\n",
    "    print(f\"Successfully loaded local dataset: {len(train_dataset)} training samples\")\n",
    "except:\n",
    "    print(\"Local dataset not found in expected format. Checking file structure...\")\n",
    "    \n",
    "    # Check if the raw files exist\n",
    "    import os\n",
    "    data_files = [\n",
    "        './data/train-images.idx3-ubyte',\n",
    "        './data/train-labels.idx1-ubyte',\n",
    "        './data/t10k-images.idx3-ubyte',\n",
    "        './data/t10k-labels.idx1-ubyte'\n",
    "    ]\n",
    "    \n",
    "    files_exist = all(os.path.exists(f) for f in data_files)\n",
    "    \n",
    "    if files_exist:\n",
    "        print(\"Raw MNIST files found! Creating dataset structure...\")\n",
    "        \n",
    "        # Create the proper directory structure for torchvision\n",
    "        processed_dir = './data/MNIST/processed'\n",
    "        raw_dir = './data/MNIST/raw'\n",
    "        os.makedirs(processed_dir, exist_ok=True)\n",
    "        os.makedirs(raw_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy files to expected locations if they don't exist\n",
    "        import shutil\n",
    "        file_mapping = {\n",
    "            './data/train-images.idx3-ubyte': './data/MNIST/raw/train-images-idx3-ubyte',\n",
    "            './data/train-labels.idx1-ubyte': './data/MNIST/raw/train-labels-idx1-ubyte',\n",
    "            './data/t10k-images.idx3-ubyte': './data/MNIST/raw/t10k-images-idx3-ubyte',\n",
    "            './data/t10k-labels.idx1-ubyte': './data/MNIST/raw/t10k-labels-idx1-ubyte'\n",
    "        }\n",
    "        \n",
    "        for src, dst in file_mapping.items():\n",
    "            if os.path.exists(src) and not os.path.exists(dst):\n",
    "                shutil.copy2(src, dst)\n",
    "                print(f\"Copied {src} to {dst}\")\n",
    "        \n",
    "        # Now try loading again\n",
    "        try:\n",
    "            train_dataset = datasets.MNIST(root='./data', train=True, download=False, transform=transform)\n",
    "            print(f\"Successfully loaded restructured local dataset: {len(train_dataset)} training samples\")\n",
    "        except:\n",
    "            print(\"Still having issues with local files. Using alternative loading method...\")\n",
    "            \n",
    "            # Alternative: Custom dataset loader for your file structure\n",
    "            class LocalMNIST(torch.utils.data.Dataset):\n",
    "                def __init__(self, images_file, labels_file, transform=None):\n",
    "                    import struct\n",
    "                    \n",
    "                    # Load images\n",
    "                    with open(images_file, 'rb') as f:\n",
    "                        magic, num_images, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "                        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "                        images = images.reshape(num_images, rows, cols)\n",
    "                    \n",
    "                    # Load labels\n",
    "                    with open(labels_file, 'rb') as f:\n",
    "                        magic, num_labels = struct.unpack('>II', f.read(8))\n",
    "                        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "                    \n",
    "                    self.images = images\n",
    "                    self.labels = labels\n",
    "                    self.transform = transform\n",
    "                \n",
    "                def __len__(self):\n",
    "                    return len(self.images)\n",
    "                \n",
    "                def __getitem__(self, idx):\n",
    "                    image = self.images[idx]\n",
    "                    label = self.labels[idx]\n",
    "                    \n",
    "                    # Convert to PIL Image for transform compatibility\n",
    "                    from PIL import Image\n",
    "                    image = Image.fromarray(image, mode='L')\n",
    "                    \n",
    "                    if self.transform:\n",
    "                        image = self.transform(image)\n",
    "                    \n",
    "                    return image, label\n",
    "            \n",
    "            # Use custom loader\n",
    "            print(\"Using custom dataset loader...\")\n",
    "            train_dataset = LocalMNIST('./data/train-images.idx3-ubyte', './data/train-labels.idx1-ubyte', transform=transform)\n",
    "            print(f\"Custom dataset loaded: {len(train_dataset)} training samples\")\n",
    "    else:\n",
    "        print(\"Raw MNIST files not found. Downloading dataset...\")\n",
    "        train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(f\"Dataset loaded: {len(train_dataset)} training samples\")\n",
    "\n",
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # First layer\n",
    "            nn.Linear(noise_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Second layer\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Third layer\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Output layer\n",
    "            nn.Linear(1024, 784),  # 28*28 = 784\n",
    "            nn.Tanh()  # Output in [-1, 1] to match normalized data\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # First layer\n",
    "            nn.Linear(784, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Second layer\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Third layer\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Output layer\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()  # Output probability [0, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize networks\n",
    "generator = Generator(NOISE_DIM).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Initialize weights\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "generator.apply(weights_init)\n",
    "discriminator.apply(weights_init)\n",
    "\n",
    "print(\"Networks initialized\")\n",
    "print(f\"Generator parameters: {sum(p.numel() for p in generator.parameters())}\")\n",
    "print(f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters())}\")\n",
    "\n",
    "# Loss function and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(BETA1, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(BETA1, 0.999))\n",
    "\n",
    "# Labels for real and fake samples\n",
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "# Fixed noise for consistent visualization\n",
    "fixed_noise = torch.randn(64, NOISE_DIM, device=device)\n",
    "\n",
    "# Training history\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "D_real_accuracy = []\n",
    "D_fake_accuracy = []\n",
    "\n",
    "def save_generated_images(generator, epoch, noise, save_path):\n",
    "    \"\"\"Save a grid of generated images\"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        fake_images = generator(noise).detach().cpu()\n",
    "        fake_images = fake_images.view(-1, 1, 28, 28)\n",
    "        fake_images = (fake_images + 1) / 2  # Denormalize from [-1,1] to [0,1]\n",
    "        \n",
    "        # Create a grid of images\n",
    "        fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
    "        fig.suptitle(f'Generated Images - Epoch {epoch}', fontsize=16)\n",
    "        \n",
    "        for i in range(64):\n",
    "            row, col = i // 8, i % 8\n",
    "            axes[row, col].imshow(fake_images[i, 0], cmap='gray')\n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    generator.train()\n",
    "\n",
    "def calculate_accuracy(predictions, targets):\n",
    "    \"\"\"Calculate accuracy for discriminator predictions\"\"\"\n",
    "    predicted = (predictions > 0.5).float()\n",
    "    correct = (predicted == targets).float().sum()\n",
    "    return correct / targets.size(0)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_G_loss = 0.0\n",
    "    epoch_D_loss = 0.0\n",
    "    epoch_D_real_acc = 0.0\n",
    "    epoch_D_fake_acc = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for i, (real_images, _) in enumerate(train_loader):\n",
    "        batch_size = real_images.size(0)\n",
    "        real_images = real_images.to(device)\n",
    "        \n",
    "        # Create labels\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "        \n",
    "        # ============================================\n",
    "        # Train Discriminator: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        # ============================================\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # Train with real images\n",
    "        real_images_flat = real_images.view(batch_size, -1)\n",
    "        output_real = discriminator(real_images_flat).view(-1)\n",
    "        loss_D_real = criterion(output_real, real_labels)\n",
    "        \n",
    "        # Train with fake images\n",
    "        noise = torch.randn(batch_size, NOISE_DIM, device=device)\n",
    "        fake_images = generator(noise)\n",
    "        output_fake = discriminator(fake_images.detach()).view(-1)\n",
    "        loss_D_fake = criterion(output_fake, fake_labels)\n",
    "        \n",
    "        # Total discriminator loss\n",
    "        loss_D = loss_D_real + loss_D_fake\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # Calculate discriminator accuracy\n",
    "        acc_real = calculate_accuracy(output_real, real_labels)\n",
    "        acc_fake = calculate_accuracy(output_fake, fake_labels)\n",
    "        \n",
    "        # ============================================\n",
    "        # Train Generator: maximize log(D(G(z)))\n",
    "        # ============================================\n",
    "        generator.zero_grad()\n",
    "        \n",
    "        # Generate fake images and get discriminator's opinion\n",
    "        output_fake_for_G = discriminator(fake_images).view(-1)\n",
    "        # Generator wants discriminator to think fake images are real\n",
    "        loss_G = criterion(output_fake_for_G, real_labels)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Accumulate losses and accuracies\n",
    "        epoch_G_loss += loss_G.item()\n",
    "        epoch_D_loss += loss_D.item()\n",
    "        epoch_D_real_acc += acc_real.item()\n",
    "        epoch_D_fake_acc += acc_fake.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Print progress\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] Batch [{i}/{len(train_loader)}] '\n",
    "                  f'D_loss: {loss_D.item():.4f} G_loss: {loss_G.item():.4f} '\n",
    "                  f'D_real_acc: {acc_real.item():.4f} D_fake_acc: {acc_fake.item():.4f}')\n",
    "    \n",
    "    # Calculate average losses and accuracies for the epoch\n",
    "    avg_G_loss = epoch_G_loss / num_batches\n",
    "    avg_D_loss = epoch_D_loss / num_batches\n",
    "    avg_D_real_acc = epoch_D_real_acc / num_batches\n",
    "    avg_D_fake_acc = epoch_D_fake_acc / num_batches\n",
    "    \n",
    "    # Store losses for plotting\n",
    "    G_losses.append(avg_G_loss)\n",
    "    D_losses.append(avg_D_loss)\n",
    "    D_real_accuracy.append(avg_D_real_acc)\n",
    "    D_fake_accuracy.append(avg_D_fake_acc)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] Average - D_loss: {avg_D_loss:.4f} '\n",
    "          f'G_loss: {avg_G_loss:.4f} D_real_acc: {avg_D_real_acc:.4f} '\n",
    "          f'D_fake_acc: {avg_D_fake_acc:.4f}')\n",
    "    \n",
    "    # Save generated images every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        save_path = f'generated_images/epoch_{epoch+1:02d}.png'\n",
    "        save_generated_images(generator, epoch+1, fixed_noise, save_path)\n",
    "        print(f'Generated images saved to {save_path}')\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# ============================================\n",
    "# Plotting Results\n",
    "# ============================================\n",
    "\n",
    "# Plot training losses\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss curves\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(G_losses, label='Generator Loss', color='blue')\n",
    "plt.plot(D_losses, label='Discriminator Loss', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Discriminator accuracy on real images\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(D_real_accuracy, label='Real Images', color='green')\n",
    "plt.plot(D_fake_accuracy, label='Fake Images', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Discriminator Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Combined view of discriminator performance\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot([(1 - acc) for acc in D_fake_accuracy], label='Generator Success Rate', color='purple')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Rate')\n",
    "plt.title('Generator Success Rate\\n(1 - D_fake_accuracy)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# Generate Final Results\n",
    "# ============================================\n",
    "\n",
    "# Generate final batch of images\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    final_noise = torch.randn(64, NOISE_DIM, device=device)\n",
    "    final_fake_images = generator(final_noise).detach().cpu()\n",
    "    final_fake_images = final_fake_images.view(-1, 1, 28, 28)\n",
    "    final_fake_images = (final_fake_images + 1) / 2  # Denormalize\n",
    "\n",
    "# Display final results\n",
    "fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n",
    "fig.suptitle('Final Generated MNIST Digits', fontsize=16)\n",
    "\n",
    "for i in range(64):\n",
    "    row, col = i // 8, i % 8\n",
    "    axes[row, col].imshow(final_fake_images[i, 0], cmap='gray')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_generated_digits.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# Analysis and Metrics\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nFinal Losses:\")\n",
    "print(f\"Generator Loss: {G_losses[-1]:.4f}\")\n",
    "print(f\"Discriminator Loss: {D_losses[-1]:.4f}\")\n",
    "\n",
    "print(f\"\\nFinal Accuracies:\")\n",
    "print(f\"Discriminator on Real Images: {D_real_accuracy[-1]:.4f}\")\n",
    "print(f\"Discriminator on Fake Images: {D_fake_accuracy[-1]:.4f}\")\n",
    "print(f\"Generator Success Rate: {1 - D_fake_accuracy[-1]:.4f}\")\n",
    "\n",
    "print(f\"\\nTraining Stability Metrics:\")\n",
    "loss_variance_G = np.var(G_losses[-10:])  # Variance in last 10 epochs\n",
    "loss_variance_D = np.var(D_losses[-10:])\n",
    "print(f\"Generator Loss Variance (last 10 epochs): {loss_variance_G:.6f}\")\n",
    "print(f\"Discriminator Loss Variance (last 10 epochs): {loss_variance_D:.6f}\")\n",
    "\n",
    "# Check for mode collapse indicators\n",
    "print(f\"\\nMode Collapse Indicators:\")\n",
    "print(f\"Discriminator accuracy on fake images should be around 0.5 for balanced training\")\n",
    "print(f\"Current D_fake accuracy: {D_fake_accuracy[-1]:.4f}\")\n",
    "if D_fake_accuracy[-1] < 0.3:\n",
    "    print(\"⚠️  Generator may be fooling discriminator too easily\")\n",
    "elif D_fake_accuracy[-1] > 0.7:\n",
    "    print(\"⚠️  Discriminator may be too strong, hampering generator learning\")\n",
    "else:\n",
    "    print(\"✅ Training appears balanced\")\n",
    "\n",
    "print(f\"\\nNetwork Architecture Summary:\")\n",
    "print(f\"Generator: {NOISE_DIM} → 256 → 512 → 1024 → 784\")\n",
    "print(f\"Discriminator: 784 → 512 → 256 → 128 → 1\")\n",
    "\n",
    "# Save training history\n",
    "training_history = {\n",
    "    'generator_losses': G_losses,\n",
    "    'discriminator_losses': D_losses,\n",
    "    'discriminator_real_accuracy': D_real_accuracy,\n",
    "    'discriminator_fake_accuracy': D_fake_accuracy\n",
    "}\n",
    "\n",
    "torch.save(training_history, 'training_history.pt')\n",
    "torch.save(generator.state_dict(), 'generator_final.pt')\n",
    "torch.save(discriminator.state_dict(), 'discriminator_final.pt')\n",
    "\n",
    "print(f\"\\nModels and training history saved!\")\n",
    "print(f\"Generated images saved in 'generated_images/' directory\")\n",
    "print(f\"Training curves saved as 'training_curves.png'\")\n",
    "print(f\"Final results saved as 'final_generated_digits.png'\")\n",
    "\n",
    "# ============================================\n",
    "# Advanced Analysis Functions\n",
    "# ============================================\n",
    "\n",
    "def analyze_digit_diversity():\n",
    "    \"\"\"Analyze the diversity of generated digits\"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        # Generate a large batch for analysis\n",
    "        noise = torch.randn(1000, NOISE_DIM, device=device)\n",
    "        generated = generator(noise).detach().cpu()\n",
    "        generated = generated.view(-1, 28, 28)\n",
    "        generated = (generated + 1) / 2  # Denormalize\n",
    "        \n",
    "        # Calculate some basic diversity metrics\n",
    "        pixel_variance = torch.var(generated, dim=0).mean().item()\n",
    "        print(f\"\\nDiversity Analysis:\")\n",
    "        print(f\"Average pixel variance across generated samples: {pixel_variance:.6f}\")\n",
    "        \n",
    "        return generated\n",
    "\n",
    "def interpolation_analysis():\n",
    "    \"\"\"Generate interpolation between two noise vectors\"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        # Create two random noise vectors\n",
    "        z1 = torch.randn(1, NOISE_DIM, device=device)\n",
    "        z2 = torch.randn(1, NOISE_DIM, device=device)\n",
    "        \n",
    "        # Create interpolation\n",
    "        alphas = torch.linspace(0, 1, 10)\n",
    "        interpolated_images = []\n",
    "        \n",
    "        for alpha in alphas:\n",
    "            z_interp = alpha * z1 + (1 - alpha) * z2\n",
    "            img = generator(z_interp).detach().cpu()\n",
    "            img = img.view(28, 28)\n",
    "            img = (img + 1) / 2  # Denormalize\n",
    "            interpolated_images.append(img)\n",
    "        \n",
    "        # Plot interpolation\n",
    "        fig, axes = plt.subplots(1, 10, figsize=(20, 2))\n",
    "        fig.suptitle('Noise Vector Interpolation', fontsize=14)\n",
    "        \n",
    "        for i, img in enumerate(interpolated_images):\n",
    "            axes[i].imshow(img, cmap='gray')\n",
    "            axes[i].set_title(f'α={alphas[i]:.1f}')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('interpolation_analysis.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# Run additional analyses\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ADDITIONAL ANALYSES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "analyze_digit_diversity()\n",
    "interpolation_analysis()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXERCISE COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
